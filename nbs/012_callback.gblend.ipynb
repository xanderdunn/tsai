{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callback.gblend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Blending\n",
    "\n",
    "> Callback used to apply gradient blending to multi-modal models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an unofficial PyTorch implementation by Ignacio Oguiza (timeseriesAI@gmail.com) based on: Wang, W., Tran, D., & Feiszli, M. (2020). **What Makes Training Multi-Modal Classification Networks Hard?**. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 12695-12705)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.callback.all import *\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.preprocessing import *\n",
    "from tsai.data.transforms import *\n",
    "from tsai.models.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GBlendLoss(Module):\n",
    "    \"Wrapper loss used by the gradient blending callback to allow weights applied to each modality.\"\n",
    "\n",
    "    def __init__(self, crit=None, w=None):\n",
    "        self.crit = ifnone(crit, CrossEntropyLossFlat())\n",
    "        self.w = w\n",
    "        \n",
    "    def forward(self, preds, target):\n",
    "        # unweighted loss\n",
    "        if not is_listy(preds): return self.crit(preds, target)\n",
    "        \n",
    "        # weighted loss\n",
    "        if self.w is None: self.w = tensor([1.] * len(preds))\n",
    "        loss = 0\n",
    "        for i, pred in enumerate(preds): loss += self.crit(pred, target) * self.w[i]\n",
    "        return loss / sum(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GBlend(Callback):\n",
    "    r\"\"\"A callback to implement multi-modal gradient blending.\n",
    "    \n",
    "    This is an unofficial PyTorch implementation by Ignacio Oguiza of  - oguiza@gmail.com based on: Wang, W., Tran, D., & Feiszli, M. (2020). \n",
    "    What Makes Training Multi-Modal Classification Networks Hard?. In Proceedings of the IEEE/CVF Conference on Computer Vision and \n",
    "    Pattern Recognition (pp. 12695-12705).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, V_pct=.1, n:Union[None, int, tuple, list]=(10, 5), sel_metric:Optional[str]=None, show_plot:bool=False, path:str='./data/gblend'): \n",
    "        \n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            V_pct      : subset of train where OGR will be measured (to estimate L*)\n",
    "            n          : None: offline learning, int: super-epoch (online learning), tuple: (warmup super-epoch, super-epoch)(online learning with warm up)\n",
    "            sel_metric : which metric will be used to calculate overfitting and generalization during training. If None, loss will be used.\n",
    "            show_plot  : will show a plot with the wieghts at the end of training\n",
    "        \"\"\"\n",
    "        assert V_pct < 1, 'V_pct must be < 1'\n",
    "        self.V_pct, self.n, self.sel_metric, self.show_plot = V_pct, n, sel_metric, show_plot\n",
    "        self.metric_idx = None\n",
    "        self.path = Path(path)\n",
    "        if not os.path.exists(self.path): os.makedirs(self.path)\n",
    "\n",
    "    def before_fit(self):\n",
    "        \n",
    "        # model\n",
    "        self.learn.M = self.model.M \n",
    "        self.old_multi_output = self.learn.model.multi_output\n",
    "        self.learn.model.multi_output = True\n",
    "\n",
    "        #loss\n",
    "        if cls_name(self.learn.loss_func) != 'GBlendLoss': self.learn.loss_func = GBlendLoss(crit=self.learn.loss_func)\n",
    "\n",
    "        # calculate super_epochs\n",
    "        if self.n is None: \n",
    "            self.super_epochs = [0]\n",
    "        else: \n",
    "            if is_listy(self.n): \n",
    "                self.wu_n = self.n[0]\n",
    "                self.n = self.n[1]\n",
    "            else: \n",
    "                self.wu_n = self.n\n",
    "            rng = range(int(max(0, self.n_epoch - self.wu_n) / self.n + 1))\n",
    "            self.super_epochs = []\n",
    "            for i in rng: \n",
    "                self.super_epochs.append((i * self.wu_n) if i <= 1 else int((i + self.wu_n / self.n - 1) * self.n))\n",
    "        self.super_epochs.append(self.n_epoch)\n",
    "        \n",
    "        # create T'(Tp) and V dataloaders\n",
    "        n_out = len(self.learn.dls.train.dataset.ptls) - self.learn.dls.train.dataset.n_inp\n",
    "        train_targets = self.learn.dls.train.dataset.ptls[-n_out]\n",
    "        Tp_idx, V_idx = get_splits(train_targets, valid_size=self.V_pct)\n",
    "        _Tp_train_dls = []\n",
    "        _V_train_dls = []\n",
    "        self.learn.new_dls = []\n",
    "        for dl in self.learn.dls[0].loaders: # train MixedDataLoaders\n",
    "            _Tp_dl = get_subset_dl(dl, Tp_idx)\n",
    "            _V_dl = get_subset_dl(dl, V_idx)\n",
    "            _Tp_train_dls.append(_Tp_dl)\n",
    "            _V_train_dls.append(_V_dl) \n",
    "            self.learn.new_dls.append(DataLoaders(_Tp_dl, _V_dl, device=self.learn.dls.device))\n",
    "        self.learn.new_dls.append(MixedDataLoaders(MixedDataLoader(*_Tp_train_dls, shuffle=True),  # train - train\n",
    "                                                   MixedDataLoader(*_V_train_dls, shuffle=False),  # train - valid\n",
    "                                                   device=self.learn.dls.device))\n",
    "        \n",
    "        # prepare containers\n",
    "        self.learn.LT = []\n",
    "        self.learn.LV = []\n",
    "\n",
    "    def before_train(self):\n",
    "        if self.epoch in self.super_epochs[:-1] and not 'LRFinder' in [cls_name(cb) for cb in self.learn.cbs]: \n",
    "            self.train_epochs = np.diff(self.super_epochs)[self.super_epochs.index(self.epoch)]\n",
    "            \n",
    "            #compute weights\n",
    "            self.learn.save('gblend_learner')\n",
    "            torch.save(self.learn.model, self.path/'gblend_model')\n",
    "            w = self.compute_weights()\n",
    "            if self.epoch == 0: self.learn.ws = [w]\n",
    "            else: self.learn.ws.append(w)\n",
    "            self.learn = self.learn.load('gblend_learner')\n",
    "            self.learn.loss_func.w = w\n",
    "\n",
    "    def compute_weights(self):\n",
    "\n",
    "        # _LT0 = []\n",
    "        # _LV0 = []\n",
    "        _LT = []\n",
    "        _LV = []\n",
    "        for i in range(self.learn.M + 1):            \n",
    "            model = torch.load(self.path/'gblend_model')\n",
    "            learn = Learner(self.learn.new_dls[i], model.m[i], loss_func=GBlendLoss(), \n",
    "                            opt_func=self.learn.opt_func, metrics=self.learn.metrics)\n",
    "            learn.model.multi_output = False\n",
    "            learn.remove_cbs(learn.cbs[1])\n",
    "            learn.add_cb(Recorder(train_metrics=True))\n",
    "            with learn.no_bar():\n",
    "                with learn.no_logging(): \n",
    "                    learn.fit_one_cycle(self.train_epochs, pct_start=0)\n",
    "            if self.metric_idx is None and self.sel_metric is not None:\n",
    "                metric_names = learn.recorder.metric_names[1:-1]\n",
    "                self.metric_idx = [i for i,m in enumerate(metric_names) if self.sel_metric in m]\n",
    "            else: self.metric_idx = [0, 1]\n",
    "            metric_values = learn.recorder.values[-1][self.metric_idx]\n",
    "            _LT.append(metric_values[0])\n",
    "            _LV.append(metric_values[1])\n",
    "\n",
    "        # if self.epoch == 0: self.compute_previous_metrics()\n",
    "        self.compute_previous_metrics()\n",
    "        self.learn.LT.append(_LT)\n",
    "        self.learn.LV.append(_LV)\n",
    "\n",
    "        LT1 = array(self.learn.LT[-2])\n",
    "        LT2 = array(self.learn.LT[-1])\n",
    "        LV1 = array(self.learn.LV[-2])\n",
    "        LV2 = array(self.learn.LV[-1])\n",
    "\n",
    "        ΔG = (LV1 - LV2) if self.metric_idx[0] == 0 else (LV2 - LV1)\n",
    "        O1 = (LV1 - LT1) if self.metric_idx[0] == 0 else (LT1 - LV1)\n",
    "        O2 = (LV2 - LT2) if self.metric_idx[0] == 0 else (LT2 - LV2)\n",
    "\n",
    "        ΔG = np.maximum(0, ΔG)\n",
    "\n",
    "        ΔO = O2 - O1\n",
    "        ΔO2 = np.maximum(1e-8, (O2 - O1)**2)\n",
    "        w = np.maximum(1e-8, np.nan_to_num(ΔG / ΔO2))\n",
    "        w = w / w.sum()\n",
    "        w = w.tolist()\n",
    "        return w\n",
    "\n",
    "    def compute_previous_metrics(self):\n",
    "        if self.metric_idx[0] == 0:  metric = self.loss_func\n",
    "        else: metric = self.learn.metrics[(min(array(self.metric_idx) - 2) - 1) // 2]\n",
    "        _LT = []\n",
    "        _LV = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.learn.M + 1):\n",
    "                model = torch.load(self.path/'gblend_model')\n",
    "                model.multi_output = False\n",
    "                model = model.m[i]\n",
    "                _train_metrics = []\n",
    "                _valid_metrics = []\n",
    "                for j,dl in enumerate(self.learn.new_dls[i]):\n",
    "                    it = iter(dl)\n",
    "                    _preds = []\n",
    "                    _targets = []\n",
    "                    for b in it: \n",
    "                        _preds.extend(model(*b[:-1]))\n",
    "                        _targets.extend(b[-1])\n",
    "                    _preds, _targets = stack(_preds), stack(_targets)\n",
    "                    try: _metric_values = metric(_preds, _targets).cpu().item()\n",
    "                    except: _metric_values = metric(torch.argmax(_preds, 1), _targets).cpu().item()\n",
    "                    if j == 0: _LT.append(_metric_values)\n",
    "                    else: _LV.append(_metric_values)\n",
    "            self.learn.LT.append(_LT)\n",
    "            self.learn.LV.append(_LV)\n",
    "\n",
    "    def after_fit(self):\n",
    "        if hasattr(self.learn, \"ws\") and self.show_plot:\n",
    "            widths = np.diff(self.super_epochs)\n",
    "            cum_ws = 0\n",
    "            for i in range(self.learn.M + 1):\n",
    "                plt.bar(self.super_epochs[:-1] + widths/2, stack(self.learn.ws)[:, i], bottom=cum_ws, width=widths, \n",
    "                        label=f'k={i+1}' if i < self.learn.M else f'fused')\n",
    "                cum_ws += stack(self.learn.ws)[:, i]\n",
    "            plt.xlim(0, self.super_epochs[-1])\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xticks(self.super_epochs)\n",
    "            plt.legend(loc='best')\n",
    "            plt.title('Online G-Blend Weights by modality')\n",
    "            plt.show()\n",
    "\n",
    "        self.learn.model.multi_output = self.old_multi_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import *\n",
    "from tsai.data.all import *\n",
    "from tsai.models.utils import *\n",
    "from tsai.models.XCM import *\n",
    "from tsai.models.TabModel import *\n",
    "from tsai.models.MultiInputNet import *\n",
    "from tsai.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:04<00:00,  8.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False)\n",
    "ts_features_df = get_ts_features(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.807015</td>\n",
       "      <td>1.592031</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.895593</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw ts\n",
    "tfms  = [None, [Categorize()]]\n",
    "batch_tfms = TSStandardize()\n",
    "ts_dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "ts_model = build_ts_model(XCM, dls=ts_dls, window_perc=.5)\n",
    "\n",
    "# ts features\n",
    "cat_names = None\n",
    "cont_names = ts_features_df.columns[:-2]\n",
    "y_names = 'target'\n",
    "tab_dls = get_tabular_dls(ts_features_df, cat_names=cat_names, cont_names=cont_names, y_names=y_names, splits=splits)\n",
    "tab_model = build_tabular_model(TabModel, dls=tab_dls)\n",
    "\n",
    "# mixed\n",
    "mixed_dls = get_mixed_dls(ts_dls, tab_dls)\n",
    "MultiModalNet = MultiInputNet(ts_model, tab_model, c_out=mixed_dls.c)\n",
    "gblend = GBlend(V_pct=.5, n=(10, 5), sel_metric=None)\n",
    "learn = Learner(mixed_dls, MultiModalNet, metrics=[accuracy, RocAuc()], cbs=gblend)\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
